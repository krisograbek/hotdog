{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hotdog_VGG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ipLIV3ct8tv"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/krisograbek/hotdog/blob/main/api/VGG_training.ipynb)\n",
        "<p align=\"center\">\n",
        "    <a href=\"https://colab.research.google.com/github/krisograbek/hotdog/blob/main/api/VGG_training.ipynb\">\n",
        "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "    </a>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPcxc_zuNczO"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The purpose of this notebook is to train an image classification model for the Hot Dog Not Hot Dog dataset. The notebook consists of the following steps:\n",
        "\n",
        " - Using kaggle API for downloading\n",
        " - Applying Data Augmentation with `ImageDataGenerator`\n",
        " - Applying Transfer Learning for the VGG19 model\n",
        " - Restoring a model with the lowest validation loss\n",
        " - Applying Early stopping [optional]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXwkrg2lK3XB"
      },
      "source": [
        "## Apply kaggle API\n",
        "\n",
        "We'll use kaggle API in order to download the Hot Dog - Not Hot Dog dataset. [Link to dataset](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog). We chose to use kaggle because this is a reliable source. Usually, many links for downloading datasets are outdated. On kaggle, datasets stay for years. \n",
        "\n",
        "In order to use kaggle API you need a kaggle account with a valid API key. All the steps are explained under [Easiest way to download kaggle data in Google Colab](https://www.kaggle.com/general/74235)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9ZhgyV5XPQD"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbvclRuuSQ6C"
      },
      "source": [
        "Please uncomment the following cell. I commented it because my API Key would be visible in the output of the cell. I wanted to hide it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SdIAmzWz51t"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xNjWEfi1w-q",
        "outputId": "56b0c26a-6369-43dd-80c1-9dd8fde276d8"
      },
      "source": [
        "# create a dir for kaggle API\n",
        "! mkdir ~/.kaggle\n",
        "# copy the json file with API Key\n",
        "! cp kaggle.json ~/.kaggle\n",
        "# make it read-only\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "# download dataset and unzip it locally\n",
        "! kaggle datasets download -d dansbecker/hot-dog-not-hot-dog -p /content/sample_data/ --unzip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading hot-dog-not-hot-dog.zip to /content/sample_data\n",
            " 93% 83.0M/89.3M [00:00<00:00, 135MB/s]\n",
            "100% 89.3M/89.3M [00:00<00:00, 140MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdzOHLqhWCuK"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1WDqtECRxts"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Vcm3xY2UBN"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEVHQoDRPzDC"
      },
      "source": [
        "Make the results reproducible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37gc0tF8PvZ3"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(31)\n",
        "from tensorflow import random\n",
        "random.set_seed(21)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aW0F_xbR0FU"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "The dataset is relatively small. It contains only 498 images in the train set. Applying Data Augmentation is a very convienient way to artifficially increase the number of train images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MQerYmp61r-"
      },
      "source": [
        "# Instantiate two image generator classes:\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    data_format='channels_last',\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='reflect')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    data_format='channels_last')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW85XJ5N6330",
        "outputId": "a2becf09-8205-4de9-c391-c899e30f4c3f"
      },
      "source": [
        "# Define the batch size:\n",
        "batch_size=32\n",
        "\n",
        "# Define the train and validation generators: \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory='/content/sample_data/train',\n",
        "    target_size=(224, 224),\n",
        "    classes=['hot_dog','not_hot_dog'],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=42)\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory='/content/sample_data/test',\n",
        "    target_size=(224, 224),\n",
        "    classes=['hot_dog','not_hot_dog'],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=42)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 498 images belonging to 2 classes.\n",
            "Found 500 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pg6f18zV937"
      },
      "source": [
        "## Downloading VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7by7bV16Ieb"
      },
      "source": [
        "vgg19 = VGG19(include_top=False,\n",
        "              weights='imagenet',\n",
        "              input_shape=(224,224,3),\n",
        "              pooling=None)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRvdjwiWWK5U"
      },
      "source": [
        "### Freezing layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M9nbUDG6ut4"
      },
      "source": [
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjzG19EPWN7O"
      },
      "source": [
        "## Implementing a Keras Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OC_qgIf6xCF"
      },
      "source": [
        "# Instantiate the sequential model and add the VGG19 model: \n",
        "model = Sequential()\n",
        "model.add(vgg19)\n",
        "\n",
        "# Add the custom layers atop the VGG19 model: \n",
        "model.add(Flatten(name='flattened'))\n",
        "model.add(Dropout(0.5, name='dropout'))\n",
        "model.add(Dense(2, activation='softmax', name='predictions'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqiJM8WuWWtU"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7viq65fb7Jgg",
        "outputId": "04262450-5b51-470b-a21e-e080432dea3e"
      },
      "source": [
        "# apply early stoping if no improvement for at least 5 steps (patience)\n",
        "# set restore to True\n",
        "early_stoping_callback=keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=5, verbose=2, mode='auto',\n",
        "    baseline=None, restore_best_weights=True)\n",
        "\n",
        "checkpoint_filepath = '/content/sample_data/weights.{epoch:02d}.h5'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss', #  validation loss\n",
        "    mode='min',         # lowest possible\n",
        "    save_best_only=True)\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# train model\n",
        "history1 = model.fit(train_generator, steps_per_epoch=15, \n",
        "                    epochs=15, validation_data=valid_generator, \n",
        "                    validation_steps=15, \n",
        "                    callbacks=[\n",
        "                            #    early_stoping_callback, # early stopping \n",
        "                               model_checkpoint_callback # only best model \n",
        "                               ]\n",
        "                )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "15/15 [==============================] - 32s 1s/step - loss: 1.5638 - accuracy: 0.5258 - val_loss: 1.2757 - val_accuracy: 0.5104\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 13s 892ms/step - loss: 0.9727 - accuracy: 0.6288 - val_loss: 0.7068 - val_accuracy: 0.6771\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 13s 894ms/step - loss: 0.5061 - accuracy: 0.7489 - val_loss: 0.4428 - val_accuracy: 0.7937\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 13s 892ms/step - loss: 0.4157 - accuracy: 0.8026 - val_loss: 0.4300 - val_accuracy: 0.7958\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 13s 893ms/step - loss: 0.4126 - accuracy: 0.8219 - val_loss: 0.5218 - val_accuracy: 0.7563\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 13s 888ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.4903 - val_accuracy: 0.7688\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 13s 887ms/step - loss: 0.4226 - accuracy: 0.8133 - val_loss: 0.5667 - val_accuracy: 0.7437\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 13s 886ms/step - loss: 0.3463 - accuracy: 0.8433 - val_loss: 0.4668 - val_accuracy: 0.7812\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 13s 884ms/step - loss: 0.3382 - accuracy: 0.8348 - val_loss: 0.8229 - val_accuracy: 0.6854\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 13s 886ms/step - loss: 0.2628 - accuracy: 0.8906 - val_loss: 0.4631 - val_accuracy: 0.7875\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 13s 888ms/step - loss: 0.2638 - accuracy: 0.8970 - val_loss: 0.7805 - val_accuracy: 0.7146\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 13s 904ms/step - loss: 0.2390 - accuracy: 0.8991 - val_loss: 0.5062 - val_accuracy: 0.7729\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 13s 887ms/step - loss: 0.2380 - accuracy: 0.8948 - val_loss: 0.4860 - val_accuracy: 0.7875\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 13s 887ms/step - loss: 0.2291 - accuracy: 0.9077 - val_loss: 0.5598 - val_accuracy: 0.7542\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 13s 887ms/step - loss: 0.1981 - accuracy: 0.9206 - val_loss: 0.5444 - val_accuracy: 0.7729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiJ1-0AmWarJ"
      },
      "source": [
        "## Evaluating the Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD-OG19xQWAe"
      },
      "source": [
        "### Model after the last epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol_Id5ilF2UG",
        "outputId": "7673c45e-e45d-4eaf-ab10-bd534c381e24"
      },
      "source": [
        "score = model.evaluate(valid_generator, verbose=0)\n",
        "print(f\"Test loss: {score[0]}\")\n",
        "print(f\"Test accuracy: {score[1]}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.5517483949661255\n",
            "Test accuracy: 0.7699999809265137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp6OVbnCQcNL"
      },
      "source": [
        "### The best Model\n",
        "However, the 4th epoch had the lowest validation loss. Let's load the model and compare both models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9O3KU6kOM2r",
        "outputId": "b3186669-d2be-40c8-af2b-104ce188bb08"
      },
      "source": [
        "best_model = keras.models.load_model('/content/sample_data/weights.04.h5')\n",
        "best_score = best_model.evaluate(valid_generator, verbose=0)\n",
        "print(f\"Test loss: {best_score[0]}\")\n",
        "print(f\"Test accuracy: {best_score[1]}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.440985769033432\n",
            "Test accuracy: 0.7919999957084656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oE0DAmnQrOx"
      },
      "source": [
        "The model that we had after 4th epoch performs better. We'll use it in our app.\n",
        "\n",
        "Please, download the model to `<project dir>/api/models/hotdog_vgg.h5`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuVhzCWDTRlW"
      },
      "source": [
        "# Final Thoughts\n",
        "\n",
        "In this notebook we showed how to apply transfer learning using a VGG19 model. We achieved around 80% accuracy. It may not seem impressive. Yet, the Hot Dog Dataset is quite small. There are many images that are tricky. If an image contains only a hot dog, our model classifies it correctly with a high probability. Probably, the model could increase accuracy by applying Fine-tuning. It is out of the scope of this notebook.\n",
        "\n",
        "These steps probably won't bring any value:\n",
        "\n",
        "- we could increase the number of epochs. However, it's obvious the model starts to overfit. The difference between train and validation metrics increases.\n",
        "- applying early stopping when there are only 15 epochs isn't beneficial.\n",
        "\n",
        "Further exploration:\n",
        "\n",
        "- compare performance without Data Augmentation\n",
        "- apply Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzMTvZEHQ8p5"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}