{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from tensorflow import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "vgg19 = VGG19(include_top=False,\n",
    "              weights='imagenet',\n",
    "              input_shape=(224,224,3),\n",
    "              pooling=None)\n",
    "            "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-24 05:55:32.993255: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-24 05:55:32.993287: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-24 05:55:32.993304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kris-IdeaPad): /proc/driver/nvidia/version does not exist\n",
      "2021-09-24 05:55:32.993623: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Instantiate the sequential model and add the VGG19 model: \n",
    "model = Sequential()\n",
    "model.add(vgg19)\n",
    "\n",
    "# Add the custom layers atop the VGG19 model: \n",
    "model.add(Flatten(name='flattened'))\n",
    "model.add(Dropout(0.5, name='dropout'))\n",
    "model.add(Dense(2, activation='softmax', name='predictions'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Instantiate two image generator classes:\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    data_format='channels_last',\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    data_format='channels_last')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Define the batch size:\n",
    "batch_size=32\n",
    "\n",
    "# Define the train and validation generators: \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory='./datasets/hotdog/train',\n",
    "    target_size=(224, 224),\n",
    "    classes=['hot_dog','not_hot_dog'],\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory='./datasets/hotdog/test',\n",
    "    target_size=(224, 224),\n",
    "    classes=['hot_dog','not_hot_dog'],\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 498 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.fit(train_generator, steps_per_epoch=15, \n",
    "                    epochs=5, validation_data=valid_generator, \n",
    "                    validation_steps=15)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 86s 6s/step - loss: 0.5425 - accuracy: 0.7446 - val_loss: 0.5588 - val_accuracy: 0.7333\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 86s 6s/step - loss: 0.4344 - accuracy: 0.8069 - val_loss: 0.4612 - val_accuracy: 0.7812\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 85s 6s/step - loss: 0.4139 - accuracy: 0.7961 - val_loss: 0.5139 - val_accuracy: 0.7563\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 87s 6s/step - loss: 0.3999 - accuracy: 0.8229 - val_loss: 0.4997 - val_accuracy: 0.7625\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 89s 6s/step - loss: 0.3441 - accuracy: 0.8433 - val_loss: 0.4579 - val_accuracy: 0.7792\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f558c21eac0>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flattened (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 2)                 50178     \n",
      "=================================================================\n",
      "Total params: 20,074,562\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model.save('./models/hotdog_vgg.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "loaded_model = keras.models.load_model('./models/hotdog_vgg.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import os\n",
    "\n",
    "DATASETS = './datasets'\n",
    "HOTDOG_DIR = os.path.join(DATASETS, 'hotdog')\n",
    "TEST_DIR = os.path.join(HOTDOG_DIR, 'test')\n",
    "TRAIN_DIR = os.path.join(HOTDOG_DIR, 'train')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "TRAIN_DIR, TEST_DIR"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('./datasets/hotdog/train', './datasets/hotdog/test')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def img_to_numpy(img, resize=True):\n",
    "    image = Image.open(img)\n",
    "    if resize:\n",
    "        image = image.resize((224, 224))\n",
    "    np_image = np.array(image)\n",
    "    return np_image\n",
    "\n",
    "def load_images(data, targets):\n",
    "    path = os.path.join(data, targets)\n",
    "    files = list(os.listdir(path))\n",
    "    images = list()\n",
    "    for f in files[:1]:\n",
    "        file_path = os.path.join(path, f)\n",
    "        images.append(img_to_numpy(file_path))\n",
    "\n",
    "    return images\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "pos_images = load_images(TEST_DIR, 'hot_dog')\n",
    "neg_images = load_images(TEST_DIR, 'not_hot_dog')\n",
    "\n",
    "pos_np = np.array(pos_images)\n",
    "neg_np = np.array(neg_images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "loaded_model.predict(pos_np)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.9816425 , 0.01835755],\n",
       "       [0.7685794 , 0.23142058],\n",
       "       [0.9728262 , 0.02717385],\n",
       "       [0.9016454 , 0.09835456],\n",
       "       [0.99896955, 0.0010305 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "loaded_model.predict(neg_np)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.03280906, 0.967191  ],\n",
       "       [0.01999859, 0.9800014 ],\n",
       "       [0.4022279 , 0.59777206],\n",
       "       [0.09397189, 0.9060281 ],\n",
       "       [0.67313814, 0.32686183]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "88fcf78bee63202e52dd2cd0abd175851e4eb7a602bdff5f01d03f5cf9125d28"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}